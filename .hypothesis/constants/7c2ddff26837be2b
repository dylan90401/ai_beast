# file: /Users/wolfen/_dev/_AI_Kryptos/ai_beast/modules/llm/manager.py
# hypothesis_version: 6.150.0

[0.0, 30.0, 100, 1024, 3600, '"', '#', "'", '.', '.bin', '.gguf', '.onnx', '.pt', '.pth', '.safetensors', '/', '1.3GB', '16GB', '19GB', '2.0GB', '2.3GB', '20GB', '26GB', '274MB', '3.8GB', '4.1GB', '4.4GB', '4.7GB', '40GB', '41GB', '45MB', '5.5GB', '670MB', '7.9GB', '8.9GB', '=', '?', 'AI-Beast/1.0', 'Alibaba Qwen 2.5 72B', 'Alibaba Qwen 2.5 7B', 'All-MiniLM-L6-v2', 'B', 'BASE_DIR', 'CACHE_DIR', 'Cannot read', 'Code Llama 34B', 'Code Llama 7B', 'Cohere Command R 35B', 'Content-Length', 'Content-Type', 'DELETE', 'DeepSeek Coder 6.7B', 'Download started', 'File not found', 'GB', 'GET', 'Google Gemma 2 27B', 'Google Gemma 2 9B', 'HEAVY_DIR', 'KB', 'LLM_CACHE_DIR', 'LLM_MODELS_DIR', 'MB', 'MODELS_DIR', 'Meta Llama 3.1 70B', 'Meta Llama 3.1 8B', 'Meta Llama 3.2 1B', 'Meta Llama 3.2 3B', 'Microsoft Phi-3 Mini', 'Mistral 7B', 'Mixtral 8x7B MoE', 'Nomic Embed Text', 'Not found', 'OLLAMA_HOST', 'OLLAMA_MODELS', 'POST', 'TB', 'User-Agent', '[_-]([0-9]+bit)', 'all-minilm', 'application/json', 'beast', 'bin', 'cache', 'codellama:34b', 'codellama:7b', 'command-r:35b', 'complete', 'config', 'custom', 'deepseek-coder:6.7b', 'delete', 'desc', 'details', 'digest', 'download_id', 'downloaded', 'downloaded_human', 'downloading', 'error', 'exists', 'export ', 'external', 'free', 'free_human', 'gemma2:27b', 'gemma2:9b', 'internal', 'llama3.1:70b', 'llama3.1:8b', 'llama3.2:1b', 'llama3.2:3b', 'llm', 'location', 'message', 'metadata', 'mistral:7b', 'mixtral:8x7b', 'model', 'model_type', 'models', 'models_root', 'modified', 'modified_at', 'mxbai-embed-large', 'name', 'new_path', 'nomic-embed-text', 'ok', 'old_path', 'ollama', 'path', 'paths.env', 'percent_used', 'phi3:medium', 'phi3:mini', 'progress', 'quantization', 'qwen2.5:72b', 'qwen2.5:7b', 'sha256', 'size', 'size_bytes', 'size_human', 'source_url', 'starting', 'status', 'stream', 'success', 'tags', 'total', 'total_human', 'unknown', 'url', 'used', 'used_human', 'utf-8', 'wb']